{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b77395f",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0624786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/.draft/renderformer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Please install it from https://github.com/Dao-AILab/flash-attention.\n",
      "Falling back to sdpa.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from renderformer import RenderFormerRenderingPipeline\n",
    "\n",
    "from infer import load_single_h5_data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47f241",
   "metadata": {},
   "source": [
    "# Generate syntetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cc19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from generate_dataset import SceneGenerator\n",
    "# import asyncio\n",
    "\n",
    "\n",
    "# CONFIG = {\n",
    "#     \"DATA_PATH\": \"/home/devel/.draft/renderformer/datasets\",\n",
    "#     \"JSON_PATH\": \"/home/devel/.draft/renderformer/datasets/json\",\n",
    "#     \"H5_PATH\": \"/home/devel/.draft/renderformer/datasets/h5\",\n",
    "#     \"GT_PATH\": \"/home/devel/.draft/renderformer/datasets/gt\",\n",
    "#     \"TEMP_MESH_PATH\": \"/home/devel/.draft/renderformer/datasets/temp\",\n",
    "#     \"OBJ_PATH\": \"/home/devel/.draft/renderformer/examples/objects\",\n",
    "#     \"BASE_DIR\": \"/home/devel/.draft/renderformer/examples\",\n",
    "#     \"SCRIPT_NAME\": \"render_scene.py\",\n",
    "#     \"NUM_RANDOM_SCENES\": 5,\n",
    "#     \"MAX_CONCURRENT_TASKS\": 4,\n",
    "# }\n",
    "\n",
    "\n",
    "# generator = SceneGenerator(CONFIG)\n",
    "\n",
    "# # Asynchronous generation\n",
    "# await generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4f705",
   "metadata": {},
   "source": [
    "# Model pretrained inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b04c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Rendered images shape: torch.Size([1, 1, 512, 512, 3])\n",
      "Saved output/random_scene_0_rock_view_0.exr and output/random_scene_0_rock_view_0.png\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model_id = \"microsoft/renderformer-v1.1-swin-large\"\n",
    "pipeline = RenderFormerRenderingPipeline.from_pretrained(model_id)\n",
    "\n",
    "if device == torch.device('cuda') and os.name == 'posix':  # avoid windows\n",
    "    from renderformer_liger_kernel import apply_kernels\n",
    "    apply_kernels(pipeline.model)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "elif device == torch.device('mps'):\n",
    "    precision = 'fp32'\n",
    "    print(\"bf16 and fp16 will cause too large error in MPS, force using fp32 instead.\")\n",
    "pipeline.to(device)\n",
    "\n",
    "# Load data and move to device\n",
    "h5_file_path = \"/home/devel/.draft/renderformer/datasets/h5/random_scene_0_rock.h5\"\n",
    "data = load_single_h5_data(h5_file_path)\n",
    "\n",
    "# Add batch dimension to all tensors\n",
    "triangles = data['triangles'].unsqueeze(0).to(device)\n",
    "texture = data['texture'].unsqueeze(0).to(device)\n",
    "mask = data['mask'].unsqueeze(0).to(device)\n",
    "vn = data['vn'].unsqueeze(0).to(device)\n",
    "c2w = data['c2w'].unsqueeze(0).to(device)\n",
    "fov = data['fov'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "resolution = 512 # 256, 512, 1024\n",
    "\n",
    "rendered_imgs = pipeline(\n",
    "    triangles=triangles,\n",
    "    texture=texture,\n",
    "    mask=mask,\n",
    "    vn=vn,\n",
    "    c2w=c2w,\n",
    "    fov=fov,\n",
    "    resolution=resolution,\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "print(\"Inference completed. Rendered images shape:\", rendered_imgs.shape)\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "base_name = os.path.splitext(os.path.basename(h5_file_path))[0]\n",
    "\n",
    "nv = c2w.shape[1]\n",
    "for i in range(nv):\n",
    "    hdr_img = rendered_imgs[0, i].cpu().numpy().astype(np.float32)\n",
    "    ldr_img = np.clip(hdr_img, 0, 1)\n",
    "    ldr_img = (ldr_img * 255).astype(np.uint8)\n",
    "\n",
    "    hdr_path = os.path.join(output_dir, f\"{base_name}_view_{i}.exr\")\n",
    "    ldr_path = os.path.join(output_dir, f\"{base_name}_view_{i}.png\")\n",
    "\n",
    "    imageio.v3.imwrite(hdr_path, hdr_img)\n",
    "    imageio.v3.imwrite(ldr_path, ldr_img)\n",
    "\n",
    "    print(f\"Saved {hdr_path} and {ldr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1f4f5",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9009af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenderFormerDataset(Dataset):\n",
    "    def __init__(self, h5_dir, gt_dir, device='cuda'):\n",
    "        \"\"\"\n",
    "        Dataset для обучения RenderFormer\n",
    "        \n",
    "        Args:\n",
    "            h5_dir: путь к директории с H5 файлами сцен\n",
    "            gt_dir: путь к директории с ground truth изображениями\n",
    "            device: устройство для загрузки данных\n",
    "        \"\"\"\n",
    "        self.h5_dir = Path(h5_dir)\n",
    "        self.gt_dir = Path(gt_dir)\n",
    "        self.device = device\n",
    "        \n",
    "        # Собираем все H5 файлы\n",
    "        self.h5_files = list(self.h5_dir.glob(\"*.h5\"))\n",
    "        print(f\"Найдено {len(self.h5_files)} H5 файлов для обучения\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        h5_file = self.h5_files[idx]\n",
    "        base_name = h5_file.stem\n",
    "\n",
    "        # Загружаем данные сцены из H5\n",
    "        scene_data = load_single_h5_data(str(h5_file))\n",
    "        \n",
    "        # Загружаем ground truth изображения\n",
    "        gt_images = []\n",
    "        nv = scene_data['c2w'].shape[0]  # количество видов\n",
    "        \n",
    "        for view_idx in range(nv):\n",
    "            # gt_path = self.gt_dir / f\"{base_name}_view_{view_idx}.exr\"\n",
    "            gt_path = self.gt_dir / f\"{base_name}.png\"\n",
    "            if gt_path.exists():\n",
    "                gt_img = imageio.v3.imread(str(gt_path))\n",
    "                gt_images.append(torch.from_numpy(gt_img.astype(np.float32)))\n",
    "            else:\n",
    "                print(f\"Предупреждение: GT изображение не найдено: {gt_path}\")\n",
    "                # Создаем пустое изображение как заглушку\n",
    "                gt_images.append(torch.zeros(512, 512, 3, dtype=torch.float32))\n",
    "        \n",
    "        gt_images = torch.stack(gt_images)  # [num_views, H, W, 3]\n",
    "\n",
    "        # Scene data parsing\n",
    "        triangles = scene_data['triangles']\n",
    "        texture = scene_data['texture']\n",
    "        mask = scene_data['mask']\n",
    "        vn = scene_data['vn']\n",
    "        c2w = scene_data['c2w']\n",
    "        fov = scene_data['fov']\n",
    "        resolution = 512\n",
    "\n",
    "        return {\n",
    "            'triangles': triangles,\n",
    "            'texture': texture,\n",
    "            'mask': mask,\n",
    "            'vn': vn,\n",
    "            'c2w': c2w,\n",
    "            'fov': fov,\n",
    "            'gt_images': gt_images,\n",
    "            'resolution': resolution\n",
    "        }\n",
    "\n",
    "class RenderFormerTrainer:\n",
    "    def __init__(self, pipeline, device='cuda', learning_rate=1e-4):\n",
    "        self.pipeline = pipeline\n",
    "        self.device = device\n",
    "        self.pipeline.to(device)\n",
    "        \n",
    "        # Оптимизатор\n",
    "        self.optimizer = optim.AdamW(self.pipeline.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "        # Функция потерь\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Планировщик обучения\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=100)\n",
    "        \n",
    "        # TensorBoard для логирования\n",
    "        self.writer = SummaryWriter('runs/renderformer_training')\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        self.pipeline.model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f'Эпоха {epoch+1}')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            # Перемещаем данные на устройство\n",
    "            triangles = batch['triangles'].to(self.device)\n",
    "            texture = batch['texture'].to(self.device)\n",
    "            mask = batch['mask'].to(self.device)\n",
    "            vn = batch['vn'].to(self.device)\n",
    "            c2w = batch['c2w'].to(self.device)\n",
    "            fov = batch['fov'].unsqueeze(-1).to(self.device)  # добавляем размерность\n",
    "            gt_images = batch['gt_images'].to(self.device)\n",
    "\n",
    "            # Обнуляем градиенты\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            try:\n",
    "                rendered_images = self.pipeline(\n",
    "                    triangles=triangles,\n",
    "                    texture=texture,\n",
    "                    mask=mask,\n",
    "                    vn=vn,\n",
    "                    c2w=c2w,\n",
    "                    fov=fov,\n",
    "                    resolution=512,\n",
    "                    torch_dtype=torch.float16\n",
    "                )\n",
    "\n",
    "                print(\"Compared shapes: \")\n",
    "                print(rendered_images.shape, gt_images.shape)\n",
    "                \n",
    "                # Вычисляем потери\n",
    "                loss = self.criterion(rendered_images, gt_images)\n",
    "                \n",
    "                # Обратный проход\n",
    "                loss.backward()\n",
    "                \n",
    "                # Обрезаем градиенты\n",
    "                torch.nn.utils.clip_grad_norm_(self.pipeline.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Обновляем веса\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Обновляем прогресс-бар\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.6f}',\n",
    "                    'Avg Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
    "                })\n",
    "                \n",
    "                # Логируем в TensorBoard\n",
    "                global_step = epoch * num_batches + batch_idx\n",
    "                self.writer.add_scalar('Loss/Train_Batch', loss.item(), global_step)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка в батче {batch_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        self.train_losses.append(avg_loss)\n",
    "        \n",
    "        # Логируем среднюю потерю за эпоху\n",
    "        self.writer.add_scalar('Loss/Train_Epoch', avg_loss, epoch)\n",
    "        \n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self, dataloader, epoch):\n",
    "        self.pipeline.model.eval()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(tqdm(dataloader, desc='Валидация')):\n",
    "                # Перемещаем данные на устройство\n",
    "                triangles = batch['triangles'].to(self.device)\n",
    "                texture = batch['texture'].to(self.device)\n",
    "                mask = batch['mask'].to(self.device)\n",
    "                vn = batch['vn'].to(self.device)\n",
    "                c2w = batch['c2w'].to(self.device)\n",
    "                fov = batch['fov'].unsqueeze(-1).to(self.device)\n",
    "                gt_images = batch['gt_images'].to(self.device)\n",
    "                \n",
    "                try:\n",
    "                    # Прямой проход\n",
    "                    rendered_images = self.pipeline(\n",
    "                        triangles=triangles,\n",
    "                        texture=texture,\n",
    "                        mask=mask,\n",
    "                        vn=vn,\n",
    "                        c2w=c2w,\n",
    "                        fov=fov,\n",
    "                        resolution=512,\n",
    "                        torch_dtype=torch.float16\n",
    "                    )\n",
    "                    \n",
    "                    # Вычисляем потери\n",
    "                    loss = self.criterion(rendered_images, gt_images)\n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка в валидационном батче {batch_idx}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        self.val_losses.append(avg_loss)\n",
    "\n",
    "        # Логируем валидационную потерю\n",
    "        self.writer.add_scalar('Loss/Validation', avg_loss, epoch)\n",
    "        \n",
    "        return avg_loss\n",
    "    \n",
    "    def save_checkpoint(self, epoch, filepath):\n",
    "        \"\"\"Сохраняем чекпоинт модели\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.pipeline.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"Чекпоинт сохранен: {filepath}\")\n",
    "\n",
    "    def load_checkpoint(self, filepath):\n",
    "        \"\"\"Загружаем чекпоинт модели\"\"\"\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        self.val_losses = checkpoint['val_losses']\n",
    "        return checkpoint['epoch']\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        \"\"\"Строим график потерь\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_losses, label='Train Loss', color='blue')\n",
    "        if self.val_losses:\n",
    "            plt.plot(self.val_losses, label='Validation Loss', color='red')\n",
    "        plt.xlabel('Эпоха')\n",
    "        plt.ylabel('Потеря')\n",
    "        plt.title('График потерь обучения')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Настройка обучения\n",
    "def setup_training(device='cuda'):\n",
    "    # Пути к данным\n",
    "    h5_dir = \"/home/devel/.draft/renderformer/datasets/h5\"\n",
    "    gt_dir = \"/home/devel/.draft/renderformer/datasets/gt\"\n",
    "    \n",
    "    # Создаем датасет\n",
    "    dataset = RenderFormerDataset(h5_dir, gt_dir, device=device)\n",
    "\n",
    "    # Разделяем на train/val\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Создаем DataLoader'ы\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"Размер обучающего набора: {len(train_dataset)}\")\n",
    "    print(f\"Размер валидационного набора: {len(val_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Запуск обучения\n",
    "def train_model(pipeline, num_epochs=50, device='cuda'):\n",
    "    # Настраиваем данные\n",
    "    train_loader, val_loader = setup_training(device)\n",
    "\n",
    "    # Создаем тренер\n",
    "    trainer = RenderFormerTrainer(pipeline, device=device, learning_rate=1e-5)\n",
    "\n",
    "    # Создаем директорию для чекпоинтов\n",
    "    checkpoint_dir = Path(\"checkpoints\")\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    print(\"Начинаем обучение...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Эпоха {epoch+1}/{num_epochs} ===\")\n",
    "        \n",
    "        # Обучение\n",
    "        train_loss = trainer.train_epoch(train_loader, epoch)\n",
    "        print(f\"Средняя потеря обучения: {train_loss:.6f}\")\n",
    "    \n",
    "        # Валидация\n",
    "        if len(val_loader) > 0:\n",
    "            val_loss = trainer.validate(val_loader, epoch)\n",
    "            print(f\"Средняя потеря валидации: {val_loss:.6f}\")\n",
    "            \n",
    "            # Сохраняем лучшую модель\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                trainer.save_checkpoint(epoch, checkpoint_dir / \"best_model.pth\")\n",
    "                print(f\"Новая лучшая модель сохранена! Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # Обновляем планировщик\n",
    "        trainer.scheduler.step()\n",
    "        \n",
    "        # Сохраняем чекпоинт каждые 10 эпох\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            trainer.save_checkpoint(epoch, checkpoint_dir / f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    # Строим график потерь\n",
    "    trainer.plot_losses()\n",
    "\n",
    "    # Закрываем TensorBoard writer\n",
    "    trainer.writer.close()\n",
    "\n",
    "    print(\"Обучение завершено!\")\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 10 H5 файлов для обучения\n",
      "Размер обучающего набора: 8\n",
      "Размер валидационного набора: 2\n",
      "Начинаем обучение...\n",
      "\n",
      "=== Эпоха 1/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:   0%|                                                                                                                                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  12%|██████████████████▊                                                                                                                                   | 1/8 [00:01<00:10,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  25%|█████████████████████████████████████▌                                                                                                                | 2/8 [00:01<00:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 1: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  38%|████████████████████████████████████████████████████████▎                                                                                             | 3/8 [00:02<00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 2: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 4/8 [00:02<00:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 3: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  62%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 5/8 [00:02<00:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 4: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 6/8 [00:03<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 5: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1:  88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 7/8 [00:03<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 6: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 7: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 26397.607422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/.draft/renderformer/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чекпоинт сохранен: checkpoints/best_model.pth\n",
      "Новая лучшая модель сохранена! Val Loss: 26397.607422\n",
      "\n",
      "=== Эпоха 2/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  12%|██████████████████▊                                                                                                                                   | 1/8 [00:01<00:07,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n",
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  25%|█████████████████████████████████████▌                                                                                                                | 2/8 [00:01<00:03,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 1: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  38%|████████████████████████████████████████████████████████▎                                                                                             | 3/8 [00:01<00:02,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 2: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 4/8 [00:02<00:01,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 3: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  62%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 5/8 [00:02<00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 4: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 6/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 5: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2:  88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 7/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 6: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 7: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 26397.607422\n",
      "\n",
      "=== Эпоха 3/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:   0%|                                                                                                                                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  12%|██████████████████▊                                                                                                                                   | 1/8 [00:00<00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 0: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  25%|█████████████████████████████████████▌                                                                                                                | 2/8 [00:01<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 1: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  38%|████████████████████████████████████████████████████████▎                                                                                             | 3/8 [00:01<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 2: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  50%|███████████████████████████████████████████████████████████████████████████                                                                           | 4/8 [00:02<00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 3: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  62%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 5/8 [00:02<00:01,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 4: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 6/8 [00:02<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 5: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3:  88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 7/8 [00:03<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 6: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared shapes: \n",
      "torch.Size([1, 1, 512, 512, 3]) torch.Size([1, 1, 512, 512, 3])\n",
      "Ошибка в батче 7: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:04<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 26397.607422\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set train params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model_id = \"microsoft/renderformer-v1.1-swin-large\"\n",
    "pipeline = RenderFormerRenderingPipeline.from_pretrained(model_id)\n",
    "\n",
    "if device == torch.device('cuda') and os.name == 'posix':  # avoid windows\n",
    "    from renderformer_liger_kernel import apply_kernels\n",
    "    apply_kernels(pipeline.model)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "elif device == torch.device('mps'):\n",
    "    precision = 'fp32'\n",
    "    print(\"bf16 and fp16 will cause too large error in MPS, force using fp32 instead.\")\n",
    "\n",
    "# Start training\n",
    "trainer = train_model(pipeline, num_epochs=3, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
