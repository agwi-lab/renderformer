{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b77395f",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0624786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/.draft/renderformer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Please install it from https://github.com/Dao-AILab/flash-attention.\n",
      "Falling back to sdpa.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from renderformer import RenderFormerRenderingPipeline\n",
    "\n",
    "from infer import load_single_h5_data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47f241",
   "metadata": {},
   "source": [
    "# Generate syntetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cc19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from generate_dataset import SceneGenerator\n",
    "# import asyncio\n",
    "\n",
    "\n",
    "# CONFIG = {\n",
    "#     \"DATA_PATH\": \"/home/devel/.draft/renderformer/datasets\",\n",
    "#     \"JSON_PATH\": \"/home/devel/.draft/renderformer/datasets/json\",\n",
    "#     \"H5_PATH\": \"/home/devel/.draft/renderformer/datasets/h5\",\n",
    "#     \"GT_PATH\": \"/home/devel/.draft/renderformer/datasets/gt\",\n",
    "#     \"TEMP_MESH_PATH\": \"/home/devel/.draft/renderformer/datasets/temp\",\n",
    "#     \"OBJ_PATH\": \"/home/devel/.draft/renderformer/examples/objects\",\n",
    "#     \"BASE_DIR\": \"/home/devel/.draft/renderformer/examples\",\n",
    "#     \"SCRIPT_NAME\": \"render_scene.py\",\n",
    "#     \"NUM_RANDOM_SCENES\": 5,\n",
    "#     \"MAX_CONCURRENT_TASKS\": 4,\n",
    "# }\n",
    "\n",
    "\n",
    "# generator = SceneGenerator(CONFIG)\n",
    "\n",
    "# # Asynchronous generation\n",
    "# await generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4f705",
   "metadata": {},
   "source": [
    "# Model pretrained inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b04c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Rendered images shape: torch.Size([1, 1, 512, 512, 3])\n",
      "Saved output/random_scene_0_rock_view_0.exr and output/random_scene_0_rock_view_0.png\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model_id = \"microsoft/renderformer-v1.1-swin-large\"\n",
    "pipeline = RenderFormerRenderingPipeline.from_pretrained(model_id)\n",
    "\n",
    "if device == torch.device('cuda') and os.name == 'posix':  # avoid windows\n",
    "    from renderformer_liger_kernel import apply_kernels\n",
    "    apply_kernels(pipeline.model)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "elif device == torch.device('mps'):\n",
    "    precision = 'fp32'\n",
    "    print(\"bf16 and fp16 will cause too large error in MPS, force using fp32 instead.\")\n",
    "pipeline.to(device)\n",
    "\n",
    "# Load data and move to device\n",
    "h5_file_path = \"/home/devel/.draft/renderformer/datasets/h5/random_scene_0_rock.h5\"\n",
    "data = load_single_h5_data(h5_file_path)\n",
    "\n",
    "# Add batch dimension to all tensors\n",
    "triangles = data['triangles'].unsqueeze(0).to(device)\n",
    "texture = data['texture'].unsqueeze(0).to(device)\n",
    "mask = data['mask'].unsqueeze(0).to(device)\n",
    "vn = data['vn'].unsqueeze(0).to(device)\n",
    "c2w = data['c2w'].unsqueeze(0).to(device)\n",
    "fov = data['fov'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "resolution = 512 # 256, 512, 1024\n",
    "\n",
    "rendered_imgs = pipeline(\n",
    "    triangles=triangles,\n",
    "    texture=texture,\n",
    "    mask=mask,\n",
    "    vn=vn,\n",
    "    c2w=c2w,\n",
    "    fov=fov,\n",
    "    resolution=resolution,\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "print(\"Inference completed. Rendered images shape:\", rendered_imgs.shape)\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "base_name = os.path.splitext(os.path.basename(h5_file_path))[0]\n",
    "\n",
    "nv = c2w.shape[1]\n",
    "for i in range(nv):\n",
    "    hdr_img = rendered_imgs[0, i].cpu().numpy().astype(np.float32)\n",
    "    ldr_img = np.clip(hdr_img, 0, 1)\n",
    "    ldr_img = (ldr_img * 255).astype(np.uint8)\n",
    "\n",
    "    hdr_path = os.path.join(output_dir, f\"{base_name}_view_{i}.exr\")\n",
    "    ldr_path = os.path.join(output_dir, f\"{base_name}_view_{i}.png\")\n",
    "\n",
    "    imageio.v3.imwrite(hdr_path, hdr_img)\n",
    "    imageio.v3.imwrite(ldr_path, ldr_img)\n",
    "\n",
    "    print(f\"Saved {hdr_path} and {ldr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1f4f5",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9009af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenderFormerDataset(Dataset):\n",
    "    def __init__(self, h5_dir, gt_dir, device='cuda'):\n",
    "        \"\"\"\n",
    "        Dataset для обучения RenderFormer\n",
    "        \n",
    "        Args:\n",
    "            h5_dir: путь к директории с H5 файлами сцен\n",
    "            gt_dir: путь к директории с ground truth изображениями\n",
    "            device: устройство для загрузки данных\n",
    "        \"\"\"\n",
    "        self.h5_dir = Path(h5_dir)\n",
    "        self.gt_dir = Path(gt_dir)\n",
    "        self.device = device\n",
    "        \n",
    "        # Собираем все H5 файлы\n",
    "        self.h5_files = list(self.h5_dir.glob(\"*.h5\"))\n",
    "        print(f\"Найдено {len(self.h5_files)} H5 файлов для обучения\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        h5_file = self.h5_files[idx]\n",
    "        base_name = h5_file.stem\n",
    "\n",
    "        # Загружаем данные сцены из H5\n",
    "        scene_data = load_single_h5_data(str(h5_file))\n",
    "        \n",
    "        # Загружаем ground truth изображения\n",
    "        gt_images = []\n",
    "        nv = scene_data['c2w'].shape[0]  # количество видов\n",
    "        \n",
    "        for view_idx in range(nv):\n",
    "            # gt_path = self.gt_dir / f\"{base_name}_view_{view_idx}.exr\"\n",
    "            gt_path = self.gt_dir / f\"{base_name}.png\"\n",
    "            if gt_path.exists():\n",
    "                gt_img = imageio.v3.imread(str(gt_path))\n",
    "                gt_img = gt_img.astype(np.float32) / 255.0\n",
    "                gt_images.append(torch.from_numpy(gt_img.astype(np.float32)))\n",
    "            else:\n",
    "                print(f\"Предупреждение: GT изображение не найдено: {gt_path}\")\n",
    "                # Создаем пустое изображение как заглушку\n",
    "                gt_images.append(torch.zeros(512, 512, 3, dtype=torch.float32))\n",
    "        \n",
    "        gt_images = torch.stack(gt_images)  # [num_views, H, W, 3]\n",
    "\n",
    "        # Scene data parsing\n",
    "        triangles = scene_data['triangles']\n",
    "        texture = scene_data['texture']\n",
    "        mask = scene_data['mask']\n",
    "        vn = scene_data['vn']\n",
    "        c2w = scene_data['c2w']\n",
    "        fov = scene_data['fov']\n",
    "        resolution = 512\n",
    "\n",
    "        return {\n",
    "            'triangles': triangles,\n",
    "            'texture': texture,\n",
    "            'mask': mask,\n",
    "            'vn': vn,\n",
    "            'c2w': c2w,\n",
    "            'fov': fov,\n",
    "            'gt_images': gt_images,\n",
    "            'resolution': resolution\n",
    "        }\n",
    "\n",
    "class RenderFormerTrainer:\n",
    "    def __init__(self, pipeline, device='cuda', learning_rate=1e-4):\n",
    "        self.pipeline = pipeline\n",
    "        self.device = device\n",
    "        self.pipeline.to(device)\n",
    "        \n",
    "        # Оптимизатор\n",
    "        self.optimizer = optim.AdamW(self.pipeline.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "        # Функция потерь\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Планировщик обучения\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=100)\n",
    "        \n",
    "        # TensorBoard для логирования\n",
    "        self.writer = SummaryWriter('runs/renderformer_training')\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        self.pipeline.model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f'Эпоха {epoch+1}')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            # Перемещаем данные на устройство\n",
    "            triangles = batch['triangles'].to(self.device)\n",
    "            texture = batch['texture'].to(self.device)\n",
    "            mask = batch['mask'].to(self.device)\n",
    "            vn = batch['vn'].to(self.device)\n",
    "            c2w = batch['c2w'].to(self.device)\n",
    "            fov = batch['fov'].unsqueeze(-1).to(self.device)  # добавляем размерность\n",
    "            gt_images = batch['gt_images'].to(self.device)\n",
    "\n",
    "            # Обнуляем градиенты\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            try:\n",
    "                # Render images\n",
    "                rendered_images = self.pipeline(\n",
    "                    triangles=triangles,\n",
    "                    texture=texture,\n",
    "                    mask=mask,\n",
    "                    vn=vn,\n",
    "                    c2w=c2w,\n",
    "                    fov=fov,\n",
    "                    resolution=512,\n",
    "                    torch_dtype=torch.float32\n",
    "                )\n",
    "                # Make rendered images differentiable\n",
    "                if not rendered_images.requires_grad:\n",
    "                    # Создаем копию с включенными градиентами\n",
    "                    rendered_images = rendered_images.clone().requires_grad_(True)\n",
    "                else:\n",
    "                    # Оставляем как есть\n",
    "                    rendered_images = rendered_images\n",
    "\n",
    "                # Вычисляем потери\n",
    "                loss = self.criterion(rendered_images, gt_images)\n",
    "                \n",
    "                # Обратный проход\n",
    "                loss.backward()\n",
    "                \n",
    "                # Обрезаем градиенты\n",
    "                torch.nn.utils.clip_grad_norm_(self.pipeline.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                # Обновляем веса\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Обновляем прогресс-бар\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.6f}',\n",
    "                    'Avg Loss': f'{total_loss/(batch_idx+1):.6f}'\n",
    "                })\n",
    "                \n",
    "                # Логируем в TensorBoard\n",
    "                global_step = epoch * num_batches + batch_idx\n",
    "                self.writer.add_scalar('Loss/Train_Batch', loss.item(), global_step)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка в батче {batch_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        self.train_losses.append(avg_loss)\n",
    "        \n",
    "        # Логируем среднюю потерю за эпоху\n",
    "        self.writer.add_scalar('Loss/Train_Epoch', avg_loss, epoch)\n",
    "        \n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self, dataloader, epoch):\n",
    "        self.pipeline.model.eval()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(dataloader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(tqdm(dataloader, desc='Валидация')):\n",
    "                # Перемещаем данные на устройство\n",
    "                triangles = batch['triangles'].to(self.device)\n",
    "                texture = batch['texture'].to(self.device)\n",
    "                mask = batch['mask'].to(self.device)\n",
    "                vn = batch['vn'].to(self.device)\n",
    "                c2w = batch['c2w'].to(self.device)\n",
    "                fov = batch['fov'].unsqueeze(-1).to(self.device)\n",
    "                gt_images = batch['gt_images'].to(self.device)\n",
    "                \n",
    "                try:\n",
    "                    # Прямой проход\n",
    "                    rendered_images = self.pipeline(\n",
    "                        triangles=triangles,\n",
    "                        texture=texture,\n",
    "                        mask=mask,\n",
    "                        vn=vn,\n",
    "                        c2w=c2w,\n",
    "                        fov=fov,\n",
    "                        resolution=512,\n",
    "                        torch_dtype=torch.float32\n",
    "                    )\n",
    "                    \n",
    "                    # Вычисляем потери\n",
    "                    loss = self.criterion(rendered_images, gt_images)\n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка в валидационном батче {batch_idx}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        self.val_losses.append(avg_loss)\n",
    "\n",
    "        # Логируем валидационную потерю\n",
    "        self.writer.add_scalar('Loss/Validation', avg_loss, epoch)\n",
    "        \n",
    "        return avg_loss\n",
    "    \n",
    "    def save_checkpoint(self, epoch, filepath):\n",
    "        \"\"\"Сохраняем чекпоинт модели\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.pipeline.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"Чекпоинт сохранен: {filepath}\")\n",
    "\n",
    "    def load_checkpoint(self, filepath):\n",
    "        \"\"\"Загружаем чекпоинт модели\"\"\"\n",
    "        checkpoint = torch.load(filepath, map_location=self.device)\n",
    "        self.pipeline.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.train_losses = checkpoint['train_losses']\n",
    "        self.val_losses = checkpoint['val_losses']\n",
    "        return checkpoint['epoch']\n",
    "\n",
    "    def plot_losses(self):\n",
    "        \"\"\"Строим график потерь\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.train_losses, label='Train Loss', color='blue')\n",
    "        if self.val_losses:\n",
    "            plt.plot(self.val_losses, label='Validation Loss', color='red')\n",
    "        plt.xlabel('Эпоха')\n",
    "        plt.ylabel('Потеря')\n",
    "        plt.title('График потерь обучения')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Настройка обучения\n",
    "def setup_training(device='cuda'):\n",
    "    # Пути к данным\n",
    "    h5_dir = \"/home/devel/.draft/renderformer/datasets/h5\"\n",
    "    gt_dir = \"/home/devel/.draft/renderformer/datasets/gt\"\n",
    "    \n",
    "    # Создаем датасет\n",
    "    dataset = RenderFormerDataset(h5_dir, gt_dir, device=device)\n",
    "\n",
    "    # Разделяем на train/val\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # Создаем DataLoader'ы\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"Размер обучающего набора: {len(train_dataset)}\")\n",
    "    print(f\"Размер валидационного набора: {len(val_dataset)}\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Запуск обучения\n",
    "def train_model(pipeline, num_epochs=50, device='cuda'):\n",
    "    # Настраиваем данные\n",
    "    train_loader, val_loader = setup_training(device)\n",
    "\n",
    "    # Создаем тренер\n",
    "    trainer = RenderFormerTrainer(pipeline, device=device, learning_rate=1e-5)\n",
    "\n",
    "    # Создаем директорию для чекпоинтов\n",
    "    checkpoint_dir = Path(\"checkpoints\")\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    print(\"Начинаем обучение...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Эпоха {epoch+1}/{num_epochs} ===\")\n",
    "        \n",
    "        # Обучение\n",
    "        train_loss = trainer.train_epoch(train_loader, epoch)\n",
    "        print(f\"Средняя потеря обучения: {train_loss:.6f}\")\n",
    "    \n",
    "        # Валидация\n",
    "        if len(val_loader) > 0:\n",
    "            val_loss = trainer.validate(val_loader, epoch)\n",
    "            print(f\"Средняя потеря валидации: {val_loss:.6f}\")\n",
    "            \n",
    "            # Сохраняем лучшую модель\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                trainer.save_checkpoint(epoch, checkpoint_dir / \"best_model.pth\")\n",
    "                print(f\"Новая лучшая модель сохранена! Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # Обновляем планировщик\n",
    "        trainer.scheduler.step()\n",
    "        \n",
    "        # Сохраняем чекпоинт каждые 10 эпох\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            trainer.save_checkpoint(epoch, checkpoint_dir / f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    # Строим график потерь\n",
    "    trainer.plot_losses()\n",
    "\n",
    "    # Закрываем TensorBoard writer\n",
    "    trainer.writer.close()\n",
    "\n",
    "    print(\"Обучение завершено!\")\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab23ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 10 H5 файлов для обучения\n",
      "Размер обучающего набора: 8\n",
      "Размер валидационного набора: 2\n",
      "Начинаем обучение...\n",
      "\n",
      "=== Эпоха 1/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s, Loss=0.630174, Avg Loss=5.938420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 5.938420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация:   0%|                                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 0.344516\n",
      "Чекпоинт сохранен: checkpoints/best_model.pth\n",
      "Новая лучшая модель сохранена! Val Loss: 0.344516\n",
      "\n",
      "=== Эпоха 2/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s, Loss=41.441978, Avg Loss=5.938420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 5.938420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация:   0%|                                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 0.344516\n",
      "\n",
      "=== Эпоха 3/3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.56it/s, Loss=0.633423, Avg Loss=5.938420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря обучения: 5.938420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация:   0%|                                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предупреждение: GT изображение не найдено: /home/devel/.draft/renderformer/datasets/gt/random_scene_3_obj3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря валидации: 0.344516\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAATdtJREFUeJzt3Xd4VGX+/vF70ntCCRAghrKh9yILqICUgIiADRAhcUX4KijYFisQsNAWXSxYlyhKESXoKkVQigIiSBEEWXpRFEEhjSRD8vz+4JeRMSGQkMOEnPfruuYy85xnzvnMh0OY21PGYYwxAgAAAACb8PJ0AQAAAABwORGCAAAAANgKIQgAAACArRCCAAAAANgKIQgAAACArRCCAAAAANgKIQgAAACArRCCAAAAANgKIQgAgMssNzdXx48f1759+zxdCgDYEiEIAIDL4JdfftGoUaMUExMjPz8/RUZGqkGDBkpJSfF0aQBgOz6eLgAASqOkpCTddddd511++PBhVa9e/bLVExISoltvvVVJSUmXbZsoOXv27FGnTp3kdDr1wAMPqEWLFvLx8VFgYKCCg4M9XR4A2A4hCAAKMX78eNWsWTPfePny5T1QDa5Uw4YNk5+fn7755htVq1bN0+UAgO0RggCgED169FCrVq08XQauYN99952+/PJLff755wQgACgluCYIAC5BUlKSHA6HVq9erWHDhqlChQoKCwvT4MGD9ccff7jN/fjjj9WzZ09VrVpV/v7+ql27tiZMmKCcnBy3ebm5uXr00UcVHh6uGjVqaMmSJa5lo0ePVmhoqGJjY7V48WK31yUkJKhGjRpuY4cPH1ZgYKAcDocOHDjgGq9Ro4YSEhLc5g4dOlQBAQFauXJloe85ISFBDofjvI+/vn7+/Plq2bKlAgMDVbFiRd1555366aefLnp9f6198eLFuvbaaxUcHKzQ0FD17NlTP/zwQ74aQ0JCtG/fPsXFxSk4OFhVq1bV+PHjZYxxzTtw4IAcDoemTp1a6Hs+n/T0dD388MOKjo6Wv7+/6tatq6lTp7pt45tvvlFAQID27t2rhg0byt/fX1WqVNGwYcP0+++/u+aNHTtWvr6++u233/JtZ+jQoYqIiFBmZqar5r+eGjlu3Dg5HI58r33vvfdc/S9fvrz69++vw4cPu83p2LGjGjVqlO+1U6dOvah9Z/78+XI4HPn2v2PHjunuu+/WVVddJW9vb9efZ0hISL5tAcDlxJEgACgBI0aMUEREhMaNG6ddu3ZpxowZOnjwoFauXOn6YJqUlKSQkBA99NBDCgkJ0ZdffqkxY8YoJSVFU6ZMca1r0qRJmjp1qgYNGqSWLVvqwQcfVHZ2tj777DM1a9ZMzz77rN566y3dfPPN2rFjR4Gn6+UZM2aMMjMzL1j/2LFj9fbbb2vevHnq2LHjBef7+/vrrbfechvbsGGDpk+f7jaWd21V69at9fzzz+vXX3/Vv//9b61Zs0abN29WRESEhg0bpi5durheM2jQIPXt21c333yzaywyMlKSNGvWLMXHxysuLk6TJk1SRkaGZsyYoWuuuUabN292+xCek5Oj7t276+9//7smT56sJUuWaOzYsTpz5ozGjx9/wfd4IcYY3XTTTVqxYoXuvvtuNWvWTEuXLtWjjz6qn376SS+88IIk6cSJE8rMzNS9996r66+/Xv/3f/+nvXv36pVXXtH69eu1fv16+fv7a9CgQRo/frzmzZunESNGuLaTnZ2tDz/8ULfccosCAgKKVOOzzz6rp59+WrfffruGDBmi3377TS+99JKuu+46V/8v1ZkzZ/Tkk08WuCw+Pl7Lly/X/fffr6ZNm8rb21tvvPGGNm3adMnbBYBLYgAA+cycOdNIMhs2bLioeS1btjTZ2dmu8cmTJxtJ5uOPP3aNZWRk5Hv9sGHDTFBQkMnMzDTGGJOZmWkqVapkBgwY4JqzdetW4+3tbZo2bWqysrKMMcYcP37chIaGmpEjR7rmxcfHm5iYGNfz7du3Gy8vL9OjRw8jyezfv9+1LCYmxsTHxxtjjHn99deNJPPSSy9dsC952wkODs43Pn/+fCPJrFixwhhjTHZ2tqlUqZJp1KiROX36tGvep59+aiSZMWPGFLh+SWbs2LH5xlNTU01ERIS555573MZ/+eUXEx4e7jYeHx9vJJn777/fNZabm2t69uxp/Pz8zG+//WaMMWb//v1GkpkyZcpFvfdzLVy40EgyzzzzjNv4rbfeahwOh9mzZ48xxpixY8caSaZz587mzJkzrnl5+865fW/btq1p06aN2/oWLFjg1teDBw8aSeY///mP27y87eQ5cOCA8fb2Ns8++6zbvG3bthkfHx+38Q4dOpiGDRvme49TpkwpdN8xxphXX33V+Pv7m06dOrntf6dPnzZeXl5m2LBhbus83/4DAJcTp8MBQAkYOnSofH19Xc/vvfde+fj4aNGiRa6xwMBA18+pqak6fvy4rr32WmVkZOjHH3+UJG3btk3Hjh1zOwrSpEkTBQQEqFmzZvLz85MkVahQQdddd52++OKL89b0+OOPq0WLFrrtttvOO+fjjz/Wfffdp0cffdTt6ENJ2Lhxo44dO6b77rvP7QhGz549Va9ePX322WdFWt+yZct08uRJDRgwQMePH3c9vL291aZNG61YsSLfa859Tw6HQyNGjFB2draWL1/uNi8jI0PHjx/XH3/84XYqW2EWLVokb29vPfDAA27jDz/8sIwx+U5XfOihh+Tt7e16PmjQIFWuXNmtD4MHD9b69eu1d+9e19j777+v6OhodejQQdKfR8WOHDlSaH0LFixQbm6ubr/9drd+ValSRbGxsfn6lZOT4zbv+PHjysjIKHQbGRkZGj9+vEaMGKGrrrrKbVl6erpyc3NVoUKFQtcBAJ5ACAKAEhAbG+v2PCQkRFFRUW7XUvzwww/q27evwsPDFRYWpsjISN15552SpFOnTkmS61qNi7mAvlq1avmu7cjz9ddf67///a8mTZpU4HUikrRlyxYNGDBAOTk5btemlJSDBw9KkurWrZtvWb169VzLL9bu3bslSddff70iIyPdHp9//rmOHTvmNt/Ly0u1atVyG6tTp44kuf25SGdPB4yMjFT58uUVFBSknj17urZX2PurWrWqQkND3cbr16/vWi7J1f969eq5zfP29lZsbKxbLf369ZO/v7/ef/99SWf3i08//VQDBw50rScwMFDNmzfXG2+8oXXr1p03sOzevVvGGMXGxubr186dO/P168cff8w3b+zYsYX2YNq0acrMzNQTTzyRb1mFChUUGxurt956y/Xnc/z4cWVlZRW6TgC4HLgmCAAug5MnT6pDhw4KCwvT+PHjVbt2bQUEBGjTpk0aPXq0cnNzJemirt851+nTpwscHz16tOLi4nT99def97uFtm7dqh49eqhz58569NFHdeedd17U9UCektejWbNmqUqVKvmW+/gU/5+0oUOH6rbbblNOTo527typcePGqU+fPvluuFAc5x4BvJBy5crpxhtv1Pvvv68xY8boww8/VFZWliss53nttdfUu3dvtWvX7rzrys3NlcPh0OLFi92OQOX5680JatSooTfffNNtbP78+XrjjTcKXP/x48c1ZcoUPf744+e9Zfy8efM0cOBAxcXFuY3z3UgAPI0QBAAlYPfu3erUqZPreVpamo4ePaobbrhBkrRy5UqdOHFCCxYs0HXXXeeat3//frf1REVFSZJ+/vnnC27zp59+UtWqVfONL1y4UOvWrbvgxeeNGzfW/PnzFRgYqPnz52vo0KH6/vvvi3zx/fnExMRIknbt2qXrr7/ebdmuXbtcyy9W7dq1JUmVKlVyu5HC+eTm5mrfvn2uoz+S9L///U+S8t3FLDY21rXOuLg4ZWRk6Mknn9ShQ4fyneaVJyYmRsuXL1dqaqrb0aC8Uxvz3l/ejSt27drldmQqNzdXu3fvVvPmzd3WO3jwYPXu3VsbNmzQ+++/r+bNm6thw4Zuc66++mrt27dP33//vVJTUyVJ7777rmbNmuWaU7t2bRljVLNmTbcenE9wcHC+vm7ZsuW885955hmFhoZq5MiR553TvHlzvfnmm7r22ms1fvx4/f3vf9eUKVO0Zs2aC9YDAFbidDgAKAFvvPGGnE6n6/mMGTN05swZ9ejRQ5Jc/yf+3OtNsrOz9eqrr7qtp3Xr1goMDFRycrJr7Pvvv1dmZqa2bNmi7OxsSdLvv/+u1atXuwUq6ex1HU888YTuuOMONWvWrNCaW7RooeDgYHl5eemtt97SgQMHSuSuaXlatWqlSpUq6bXXXnM7BWrx4sXauXOnevbsWaT1xcXFKSwsTM8995xbr/MUdGvpl19+2fWzMUYvv/yyfH191blz50K3lXfUqaAjKHluuOEG5eTkuG1Dkl544QU5HA7Xn33nzp3l7++v6dOnu9Yrnb3W59dff9WNN97o9voePXqoYsWKmjRpklatWpXvKFCewMBAtWnTRl26dFGXLl3ynfp38803y9vbW4mJifmuczLG6MSJE4X2oDAHDhzQjBkzNG7cuEKPdKWkpGjQoEG66aab9NRTT6lLly6uoA8AnsSRIAAoAdnZ2ercubNuv/127dq1S6+++qquueYa3XTTTZKkdu3aqVy5coqPj9cDDzwgh8OhWbNm5ftwGhwcrJEjR2rixIny8fFRixYt9Nprr8nLy0tHjx5Vz549ddNNN+mtt95SVlaWHnnkEbfXHzlyRH5+fm43ZLgYjRo10ujRozVx4kT1799fTZo0ubSGSPL19dWkSZN01113qUOHDhowYIDrFtk1atTQgw8+WKT1hYWFacaMGRo0aJBatGih/v37KzIyUocOHdJnn32m9u3buwWSgIAALVmyRPHx8WrTpo0WL16szz77TE888YTr5gJ5du3apSVLlig3N1c7duzQlClT1Lp160KvzerVq5c6deqkJ598UgcOHFDTpk31+eef6+OPP9aoUaNcR67Kly+vp556Sk8//bTi4uLUu3dv7du3Ty+//LKaNm2qIUOG5Otb//799fLLL8vb21sDBgwoUp/y1K5dW88884wef/xxHThwQH369FFoaKj279+v5ORkDR06NN/+c7FWrVql+vXr66677ip03vDhw3X69Ol8t1MHAI/z2H3pAKAUK+otsletWmWGDh1qypUrZ0JCQszAgQPNiRMn3OauWbPG/P3vfzeBgYGmatWq5p///KdZunSp2+2PjTHG6XSaUaNGmdDQUHPVVVeZJUuWmODgYBMfH29Gjx5tQkJCTK1atcwnn3zitv6820Kfe9vsc2ss7DbHxpy9PXe9evVM69at3W7l/FcXe4vsPPPmzTPNmzc3/v7+pnz58mbgwIHmyJEj512/znOL7DwrVqwwcXFxJjw83AQEBJjatWubhIQEs3Hjxnw17t2713Tr1s0EBQWZypUrm7Fjx5qcnBzXvLxbZOc9vLy8TPXq1U18fHyhNeZJTU01Dz74oKlatarx9fU1sbGxZsqUKSY3Nzff3FdeecXUq1fP+Pr6msqVK5thw4bl20fyfPvtt0aS6dat2wVryPPXW2Tn+eijj8w111xjgoODTXBwsKlXr54ZPny42bVrl2tOUW+RLckkJye7zf3rLdrnzJljHA6HWbJkSb553CIbgKc5jLnIe4ECAPLJ+zLQDRs2qFWrVpZtJyQkRLfeeut5b3IAdwkJCfrwww+Vlpbm6VKKZevWrWrWrJneffddDRo0yNPlAECZwzVBAACUMm+++aZCQkLcvi8KAFByuCYIAIBS4r///a927NihN954QyNGjOBW0gBgEUIQAAClxP33369ff/1VN9xwgxITEz1dDgCUWVwTBAAAAMBWuCYIAAAAgK0QggAAAADYyhV9TVBubq5+/vlnhYaGyuFweLocAAAAAB5ijFFqaqqqVq0qL6/Cj/Vc0SHo559/VnR0tKfLAAAAAFBKHD58WNWrVy90zhUdgkJDQyWdfaNhYWEercXpdOrzzz9Xt27d5Ovr69FayiL6az16bC36ay36ay36ay36ay36a63S1N+UlBRFR0e7MkJhrugQlHcKXFhYWKkIQUFBQQoLC/P4DlAW0V/r0WNr0V9r0V9r0V9r0V9r0V9rlcb+XsxlMtwYAQAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICteDwE/fTTT7rzzjtVoUIFBQYGqnHjxtq4caOnywIAAABQRvl4cuN//PGH2rdvr06dOmnx4sWKjIzU7t27Va5cOU+WBQAAAKAM82gImjRpkqKjozVz5kzXWM2aNT1YEQAAAICyzqMh6JNPPlFcXJxuu+02rVq1StWqVdN9992ne+65p8D5WVlZysrKcj1PSUmRJDmdTjmdzstS8/nkbd/TdZRV9Nd69Nha9Nda9Nda9Nda9Nda9Ndapam/RanBYYwxFtZSqICAAEnSQw89pNtuu00bNmzQyJEj9dprryk+Pj7f/HHjxikxMTHf+OzZsxUUFGR5vQAAAABKp4yMDN1xxx06deqUwsLCCp3r0RDk5+enVq1aae3ata6xBx54QBs2bNC6devyzS/oSFB0dLSOHz9+wTdqNafTqWXLlqlr167y9fX1aC1lEf21Hj22Fv21Fv21Fv21Fv21Fv21Vmnqb0pKiipWrHhRIcijp8NFRUWpQYMGbmP169fXRx99VOB8f39/+fv75xv39fX1eNPzlKZayiL6az16bC36ay36ay36ay36ay36a63S0N+ibN+jIah9+/batWuX29j//vc/xcTEeKii4jFGSk+XMjO9lZ4u8fer5Dmd9Ndq9Nha9Nda9Nda9Nda9Nda9Ndaef313LllxePR0+E2bNigdu3aKTExUbfffru+/fZb3XPPPXrjjTc0cODAC74+JSVF4eHhF3XIy0rp6VJIiMc2DwAAAHjUH384FRHh+dPhLjYbePTLUlu3bq3k5GTNmTNHjRo10oQJE/Tiiy9eVAACAAAAgOLw6OlwknTjjTfqxhtv9HQZlyQo6Gz6Xbp0qeLi4jx+PmRZ5HTSX6vRY2vRX2vRX2vRX2vRX2vRX2vl9TcoKM7TpRSJx0NQWeBwSMHBUkBAjoKDOd/UCk4n/bUaPbYW/bUW/bUW/bUW/bUW/bVWXn8dDk9XUjQePR0OAAAAAC43QhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAW/FoCBo3bpwcDofbo169ep4sCQAAAEAZ5+PpAho2bKjly5e7nvv4eLwkAAAAAGWYxxOHj4+PqlSpclFzs7KylJWV5XqekpIiSXI6nXI6nZbUd7Hytu/pOsoq+ms9emwt+mst+mst+mst+mst+mut0tTfotTgMMYYC2sp1Lhx4zRlyhSFh4crICBAbdu21fPPP6+rrrrqvPMTExPzjc+ePVtBQUFWlwsAAACglMrIyNAdd9yhU6dOKSwsrNC5Hg1BixcvVlpamurWraujR48qMTFRP/30k7Zv367Q0NB88ws6EhQdHa3jx49f8I1azel0atmyZeratat8fX09WktZRH+tR4+tRX+tRX+tRX+tRX+tRX+tVZr6m5KSoooVK15UCPLo6XA9evRw/dykSRO1adNGMTEx+uCDD3T33Xfnm+/v7y9/f/98476+vh5vep7SVEtZRH+tR4+tRX+tRX+tRX+tRX+tRX+tVRr6W5Ttl6pbZEdERKhOnTras2ePp0sBAAAAUEaVqhCUlpamvXv3KioqytOlAAAAACijPBqCHnnkEa1atUoHDhzQ2rVr1bdvX3l7e2vAgAGeLAsAAABAGebRa4KOHDmiAQMG6MSJE4qMjNQ111yjb775RpGRkZ4sCwAAAEAZ5tEQNHfuXE9uHgAAAIANlaprggAAAADAaoQgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZSakLQxIkT5XA4NGrUKE+XAgAAAKAMKxUhaMOGDXr99dfVpEkTT5cCAAAAoIzz8XQBaWlpGjhwoN58800988wzhc7NyspSVlaW63lKSookyel0yul0WlrnheRt39N1lFX013r02Fr011r011r011r011r011qlqb9FqcFhjDEW1nJB8fHxKl++vF544QV17NhRzZo104svvljg3HHjxikxMTHf+OzZsxUUFGRxpQAAAABKq4yMDN1xxx06deqUwsLCCp3r0SNBc+fO1aZNm7Rhw4aLmv/444/roYcecj1PSUlRdHS0unXrdsE3ajWn06lly5apa9eu8vX19WgtZRH9tR49thb9tRb9tRb9tRb9tRb9tVZp6m/eWWIXw2Mh6PDhwxo5cqSWLVumgICAi3qNv7+//P398437+vp6vOl5SlMtZRH9tR49thb9tRb9tRb9tRb9tRb9tVZp6G9Rtu+xEPTdd9/p2LFjatGihWssJydHq1ev1ssvv6ysrCx5e3t7qjwAAAAAZZTHQlDnzp21bds2t7G77rpL9erV0+jRowlAAAAAACzhsRAUGhqqRo0auY0FBwerQoUK+cYBAAAAoKSUiu8JAgAAAIDLxePfE3SulStXeroEAAAAAGUcR4IAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2AohCAAAAICtEIIAAAAA2IqPpwsAAABA2ZKTkyOn0+npMiRJTqdTPj4+yszMVE5OjqfLKXMuZ3+9vb3l4+Mjh8NxyesiBAEAAKDEpKWl6ciRIzLGeLoUSZIxRlWqVNHhw4dL5MMz3F3u/gYFBSkqKkp+fn6XtJ5ihaDp06cXuvyBBx4oVjEAAAC4cuXk5OjIkSMKCgpSZGRkqQgdubm5SktLU0hIiLy8uBKkpF2u/hpjlJ2drd9++0379+9XbGzsJW2vWCFo1KhRql69ury9vSVJhw8fVlRUlOvwFCEIAADAfpxOp4wxioyMVGBgoKfLkXT2Q3p2drYCAgIIQRa4nP0NDAyUr6+vDh486NpmcRX7dLiNGzeqUqVKkqTQ0FCtWrVKtWrVKnYhAAAAKBtKwxEglE0lFbSKtRZvb2+3C59ycnK0bt26EikIAAAAAKxUrBBUvXp1ffHFF5KktWvXKjc3Vw899JCeeOKJUnMRHAAAAAAUpFghaNiwYUpISFC9evV0/fXX65577tHGjRu1fPlyde3ataRrBAAAAK4oNWrU0IsvvujpMnAexbom6LHHHlOLFi20detW1axZU7fccoscDoe++uorjRw5sqRrBAAAACxxoeuXxo4dq3HjxhV5vRs2bFBwcHAxqzqrY8eOatasGWHKAsW+MUK3bt3UrVs3tzF/f3+99tprl1wUAAAAcDkcPXrU9fO8efM0ZswY7dq1yzUWEhLi+tkYo5ycHPn4XPgjdGRkZMkWihJ1SbdX2Lhxo2bNmqVZs2Zp48aNJVUTAAAAygBjpPR0zzwu9jL1KlWquB7h4eFyOByu5z/++KNCQ0O1ePFitWzZUv7+/vr666+1d+9e9e7dW5UrV1ZISIhat26t5cuXu633r6fDORwOvfXWW+rbt6+CgoIUGxurTz755JL6+9FHH6lhw4by9/dXjRo19K9//ctt+auvvqrY2FgFBASocuXKuvXWW13LPvzwQzVu3FiBgYGqUKGCunTpovT09Euq50pSrCNBR44c0YABA7RmzRpFRERIkk6ePKl27dpp7ty5ql69eknWCAAAgCtQRoZ0zoGUyyotTbrEs9FcHnvsMU2dOlW1atVSuXLldPjwYd1www169tln5e/vr3fffVe9evXSrl27dNVVV513PYmJiZo8ebKmTJmil156SQMHDtTBgwdVvnz5Itf03Xff6fbbb9e4cePUr18/rV27Vvfdd58qVKighIQEbdy4UQ888IBmzZqldu3a6ffff9dXX30l6ezRrwEDBmjy5Mnq27evUlNT9dVXX9nqBmfFCkFDhgyR0+nUzp07VbduXUnSrl27dNddd2nIkCFasmRJiRYJAAAAeMr48ePdbv5Vvnx5NW3a1PV8woQJSk5O1ieffKIRI0acdz0JCQkaMGCAJOm5557T9OnT9e2336p79+5FrmnatGnq3Lmznn76aUlSnTp1tGPHDk2ZMkUJCQk6dOiQgoODdeONNyo0NFQxMTFq3ry5pLMh6MyZM7r55psVExMjSWrcuHGRa7iSFSsErVq1SmvXrnUFIEmqW7euXnrpJV177bUlVhwAAACuXEFBZ4/IeGrbJaVVq1Zuz9PS0jRu3Dh99tlnrkBx+vRpHTp0qND1NGnSxPVzcHCwwsLCdOzYsWLVtHPnTvXu3dttrH379nrxxReVk5Ojrl27KiYmRrVq1VL37t3VvXt316l4TZs2VefOndW4cWPFxcWpW7duuvXWW1WuXLli1XIlKtY1QdHR0XI6nfnGc3JyVLVq1UsuCgAAAFc+h+PsKWmeeFzgpm9F8te7vD3yyCNKTk7Wc889p6+++kpbtmxR48aNlZ2dXeh6fH19/9Ifh3Jzc0uu0HOEhoZq06ZNmjNnjqKiojRmzBg1bdpUJ0+elLe3t5YtW6bFixerQYMGeumll1S3bl3t37/fklpKo2KFoClTpuj+++93uxnCxo0bNXLkSE2dOrXEigMAAABKmzVr1ighIUF9+/ZV48aNVaVKFR04cOCy1lC/fn2tWbMmX1116tSRt7e3JMnHx0ddunTR5MmT9f333+vAgQP68ssvJZ0NYO3bt1diYqI2b94sPz8/JScnX9b34EnFOh0uISFBGRkZatOmjesWgWfOnJGPj4/+8Y9/6B//+Idr7u+//14ylQIAAAClQGxsrBYsWKBevXrJ4XDo6aeftuyIzm+//aYtW7a4jUVFRenhhx9W69atNWHCBPXr10/r1q3Tyy+/rFdffVWS9Omnn2rfvn267rrrVK5cOS1atEi5ubmqW7eu1q9fry+++ELdunVTpUqVtH79ev3222+qX7++Je+hNCpWCOILmwAAAGBX06ZN0z/+8Q+1a9dOFStW1OjRo5WSkmLJtmbPnq3Zs2e7jU2YMEFPPfWUPvjgA40ZM0YTJkxQVFSUxo8fr4SEBElSRESEFixYoHHjxikzM1OxsbGaM2eOGjZsqJ07d2r16tV68cUXlZKSopiYGP3rX/9Sjx49LHkPpVGxQlB8fHxJ1wEAAAB4VEJCgitESFLHjh0LvG10jRo1XKeV5Rk+fLjb87+eHlfQek6ePFloPStXrix0+S233KJbbrmlwGXXXHPNeV9fv35929/Nudhflrp371499dRTGjBggOuuFosXL9YPP/xQYsUBAAAAQEkrVghatWqVGjdurPXr12vBggVK+//3Pty6davGjh1bogUCAAAAQEkqVgh67LHH9Mwzz2jZsmXy8/NzjV9//fX65ptvSqw4AAAAAChpxQpB27ZtU9++ffONV6pUScePH7/kogAAAADAKsUKQRERETp69Gi+8c2bN6tatWqXXBQAAAAAWKVYIah///4aPXq0fvnlF9c33a5Zs0aPPPKIBg8eXNI1AgAAAECJKVYIeu6551SvXj1FR0crLS1NDRo00HXXXad27drpqaeeKukaAQAAAKDEFOt7gvz8/PTmm29qzJgx2rZtm9LS0tS8eXPFxsaWdH0AAAAAUKKKFYLGjx+vRx55RNHR0YqOji7pmgAAAADAMsU6HS4xMdH13UAAAACA3XXs2FGjRo1yPa9Ro4ZefPHFQl/jcDi0cOHCS952Sa3HTooVgowxJV0HAAAAcNn16tVL3bt3L3DZV199JYfDoe+//77I692wYYOGDh16qeW5GTdunJo1a5Zv/OjRo+rRo0eJbuuvkpKSFBERYek2LqdinQ4nSVOnTlVISEiBy8aMGVPsggAAAIDL5e6779Ytt9yiI0eOqHr16m7LZs6cqVatWqlJkyZFXm9kZGRJlXhBVapUuWzbKiuKdSRIktasWaMVK1bke6xcufKi1zFjxgw1adJEYWFhCgsLU9u2bbV48eLilgQAAIDSxBgpPd0zj4s8c+nGG29UZGSkkpKS3MbT0tI0f/583X333Tpx4oQGDBigatWqKSgoSI0bN9acOXMKXe9fT4fbvXu3rrvuOgUEBKhBgwZatmxZvteMHj1aderUUVBQkGrVqqWnn35aTqdT0tkjMYmJidq6dascDoccDoer5r+eDrdt2zZdf/31CgwMVIUKFTR06FC3S1kSEhLUp08fTZ06VVFRUapQoYKGDx/u2lZxHDp0SL1791ZISIjCwsJ0++2369dff3Ut37p1qzp16qTQ0FCFhYWpZcuW2rhxoyTp4MGD6tWrl8qVK6fg4GA1bNhQixYtKnYtF6PYR4KSk5NVqVKlS9p49erVNXHiRMXGxsoYo3feeUe9e/fW5s2b1bBhw0taNwAAADwsI0M6z5lDlktLk4KDLzjNx8dHgwcPVlJSkp588kk5HA5J0vz585WTk6MBAwYoLS1NLVu21OjRoxUWFqbPPvtMgwYNUu3atXX11VdfcBu5ubm6+eabVblyZa1fv16nTp1yu34oT2hoqJKSklS1alVt27ZN99xzj0JDQ/XPf/5T/fr10/bt27VkyRItX75ckhQeHp5vHenp6YqLi1Pbtm21YcMGHTt2TEOGDNGIESPcgt6KFSsUFRWlFStWaM+ePerXr5+aNWume+6554Lvp6D317dvX4WEhGjVqlU6c+aMhg8frn79+rkOkAwcOFDNmzfXjBkz5O3trS1btsjX11eSNHz4cGVnZ2v16tUKDg7Wjh07znvGWUkpdggqCb169XJ7/uyzz2rGjBn65ptvCgxBWVlZysrKcj1PSUmRJDmdzktKriUhb/uerqOsor/Wo8fWor/Wor/Wor/WKkv9dTqdMsYoNzdXubm5Um5u8U87ukR528+7lj2vroIkJCRoypQpWrFihTp27Cjp7KlwN998s0JDQxUaGqqHHnrINX/48OFasmSJ5s2bp1atWrnG/7qNvOeff/65fvzxRy1evFhVq1aVJD3zzDPq2bPnn72S9MQTT7hee9VVV+nhhx/WvHnz9Mgjj8jf31/BwcHy8fFxOxCR99q89bz33nvKzMxUUlKSgoOD1aBBA02fPl29e/fW888/r8qVK8sYo3Llymn69Ony9vZWnTp1dMMNN2j58uW6++67z9/Pc/577ntctWqVtm3bpr1797ruHJ2UlKTGjRtr/fr1at26tQ4dOqSHH35YderUkSTVrl3btb5Dhw7p5ptvdn3+r1GjRoHbyhszxsjpdMrb29ttWVH+DhUrBHXo0EF+fn7Feel55eTkaP78+UpPT1fbtm0LnPP8888rMTEx3/jnn3+uoKCgEq2nuAo6tImSQ3+tR4+tRX+tRX+tRX+tVRb66+PjoypVqigtLU3Z2dlnT0k7csQzxZw5I/3//2EuSampqeedWrVqVV199dV644031KJFC+3bt09fffWV/vvf/yolJUU5OTmaNm2akpOTdfToUTmdTmVlZcnPz8/1P+XPnDmj7Oxs1/Pc3FxlZmYqJSVFW7ZsUbVq1RQSEuJanveB//Tp066xBQsW6PXXX9eBAweUnp6uM2fOKDQ01LU8KytLOTk5rufnylvP999/r4YNG7rNa9y4sXJzc7Vp0ya1b99eTqdTderUUXp6uuv1FSpU0I4dOwpctyRlZmbKGFPg8v/973+qVq2awsPDXcurV6+u8PBwbd68WXXr1tV9992noUOH6p133lGHDh3Up08f1axZU5I0ZMgQPfzww1q8eLE6duyoXr16qVGjRgXWkZ2drdOnT2v16tU6c+aM27KMjIwCX1OQYoWgFStWuH7OS9d5hw6Latu2bWrbtq0yMzMVEhKi5ORkNWjQoMC5jz/+uFsKT0lJUXR0tLp166awsLBibb+kOJ1OLVu2TF27dnUd2kPJob/Wo8fWor/Wor/Wor/WKkv9zczM1OHDhxUSEqKAgICzgwWcsnU5GWOUmpqq0NDQQj+v3nPPPRo5cqRef/11ffjhh6pdu7Z69Oghh8OhSZMm6fXXX9e0adPUuHFjBQcH68EHH1Rubq7rM6iPj4/8/Pxcz728vBQQEKCwsDAFBATIy8vL7fNq3mfowMBAhYWFad26dRo6dKjGjRunbt26KTw8XPPmzdO0adNcr/P395e3t3eBn3vz1uPn5ycfH58CtxUcHKywsDD5+vq65ufx9/fPV+O5AgIC5HA48i3PW3dBr3U4HK4ePPfcc0pISNCiRYu0ePFiTZw4UbNnz1bfvn01YsQI9e7dW5999pmWLVum66+/XlOnTtWIESPy1ZGZmanAwEDX9VXnOl+AK0ixT4d79913NWXKFO3evVuSVKdOHT366KMaNGhQkdZTt25dbdmyRadOndKHH36o+Ph4rVq1qsAg5O/vL39//3zjvr6+peaXRmmqpSyiv9ajx9aiv9aiv9aiv9YqC/3NycmRw+GQl5eXvLw8dSKcu7xTqvLqOp/+/fvrwQcf1Ny5czVr1izde++9rtOt1q5dq969e2vw4MGude7evVsNGjRwW+dft5H3vEGDBjp8+LB+/fVXRUVFSZK+/fZbSXL16ptvvlFMTIyeeuop1+sPHTrkmiOd/Syck5NT4PvIW0+DBg30zjvv6PTp0wr+/9dErVu3Tl5eXqpfv768vLxcN1b4a63nbqug9Re0PDc3V3Xq1NHhw4f1008/uU6H27Fjh06ePKlGjRq5XlOvXj3Vq1dPDz30kAYMGKB33nlHt9xyiyQpJiZG9913n+677z49/vjjeuutt/TAAw8UWIfD4Sjw70tR/v4Ua++cNm2a7r33Xt1www364IMP9MEHH6h79+76v//7P73wwgtFWpefn5/+9re/qWXLlnr++efVtGlT/fvf/y5OWQAAAECxhISEqF+/fnr88cd19OhRJSQkuJbFxsZq2bJlWrt2rXbu3Klhw4a53fnsQrp06aI6deooPj5eW7du1VdffaUnn3zSbU5sbKwOHTqkuXPnau/evZo+fbqSk5Pd5tSoUUP79+/Xli1bdPz4cbdr5fMMHDhQAQEBio+P1/bt27VixQrdf//9GjRokCpXrly0pvxFTk6OtmzZ4vbYuXOnOnbsqMaNG2vgwIHatGmTvv32Ww0ePFgdOnRQq1atdPr0aY0YMUIrV67UwYMHtWbNGm3YsEH169eXJI0aNUpLly7V/v37tWnTJq1YscK1zCrFCkEvvfSSZsyYoUmTJummm27STTfdpMmTJ+vVV1/V9OnTL6mg3NzcAv9AAQAAACvdfffd+uOPPxQXF+e6gYEkPfXUU2rRooXi4uLUsWNHValSRX369Lno9Xp5eSk5OVmnT5/W1VdfrSFDhujZZ591m3PTTTfpwQcf1IgRI9SsWTOtXbtWTz/9tNucW265Rd27d1enTp0UGRlZ4G26g4KCtHTpUv3+++9q3bq1br31VnXu3Fkvv/xy0ZpRgLS0NDVv3tzt0bt3bzkcDiUnJ6tcuXK67rrr1KVLF9WqVUvz5s2TJHl7e+vEiRMaPHiw6tSpo9tvv109evRwXeufk5Oj4cOHq379+urevbvq1KmjV1999ZLrLYzDmIu8ifo5AgICtH37dv3tb39zG9+9e7caN26szMzMi1rP448/rh49euiqq65SamqqZs+erUmTJmnp0qXq2rXrBV+fkpKi8PBwnTp1qlRcE7Ro0SLdcMMNV/yh7NKI/lqPHluL/lqL/lqL/lqrLPU3MzNT+/fvV82aNfNdr+Epubm5SklJUVhYWKk5Ra8sudz9LWwfK0o2KFalf/vb3/TBBx/kG583b55iY2Mvej3Hjh3T4MGDVbduXXXu3FkbNmy46AAEAAAAAMVRrBsjJCYmql+/flq9erXat28vSVqzZo2++OKLAsPR+bz99tvF2TwAAAAAFFuxjgTdcsstWr9+vSpWrKiFCxdq4cKFqlixor799lv17du3pGsEAAAAgBJTpCNB5957OzY2tsALlvLOCQQAAACA0qhIISgiIuKivhQ1Jyen2AUBAADgylaM+24BF6Wk9q0iXxP04Ycfqnz58iWycQAAAJQdeV8ump2drcDAQA9Xg7IoIyNDUtG+GLUgRQ5B7du3V6VKlS5powAAACh7fHx8FBQUpN9++02+vr6l4pbUubm5ys7OVmZmZqmop6y5XP01xigjI0PHjh1TRESEK3AXV7HuDgcAAAD8lcPhUFRUlPbv36+DBw96uhxJZz88nz59WoGBgRd1WQeK5nL3NyIiQlWqVLnk9RCCAAAAUGL8/PwUGxur7OxsT5ci6eyX0a5evVrXXXfdFf9ltKXR5eyvr6/vJR8BylOkEORwOEjQAAAAKJSXl5cCAgI8XYaks9cpnTlzRgEBAYQgC1yp/S1SCDLGKCEhQf7+/oXOW7BgwSUVBQAAAABWKVIIio+Pt6oOAAAAALgsihSCZs6caVUdAAAAAHBZcJ9AAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALZCCAIAAABgK4QgAAAAALbi0RD0/PPPq3Xr1goNDVWlSpXUp08f7dq1y5MlAQAAACjjPBqCVq1apeHDh+ubb77RsmXL5HQ61a1bN6Wnp3uyLAAAAABlmI8nN75kyRK350lJSapUqZK+++47XXfddfnmZ2VlKSsry/U8JSVFkuR0OuV0Oq0t9gLytu/pOsoq+ms9emwt+mst+mst+mst+mst+mut0tTfotTgMMYYC2spkj179ig2Nlbbtm1To0aN8i0fN26cEhMT843Pnj1bQUFBl6NEAAAAAKVQRkaG7rjjDp06dUphYWGFzi01ISg3N1c33XSTTp48qa+//rrAOQUdCYqOjtbx48cv+Eat5nQ6tWzZMnXt2lW+vr4eraUsor/Wo8fWor/Wor/Wor/Wor/Wor/WKk39TUlJUcWKFS8qBHn0dLhzDR8+XNu3bz9vAJIkf39/+fv75xv39fX1eNPzlKZayiL6az16bC36ay36ay36ay36ay36a63S0N+ibL9UhKARI0bo008/1erVq1W9enVPlwMAAACgDPNoCDLG6P7771dycrJWrlypmjVrerIcAAAAADbg0RA0fPhwzZ49Wx9//LFCQ0P1yy+/SJLCw8MVGBjoydIAAAAAlFEe/Z6gGTNm6NSpU+rYsaOioqJcj3nz5nmyLAAAAABlmMdPhwMAAACAy8mjR4IAAAAA4HIjBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFUIQAAAAAFshBAEAAACwFY+GoNWrV6tXr16qWrWqHA6HFi5c6MlyAAAAANiAR0NQenq6mjZtqldeecWTZQAAAACwER9PbrxHjx7q0aOHJ0sAAAAAYDMeDUFFlZWVpaysLNfzlJQUSZLT6ZTT6fRUWa4azv0vShb9tR49thb9tRb9tRb9tRb9tRb9tVZp6m9RanAYY4yFtVw0h8Oh5ORk9enT57xzxo0bp8TExHzjs2fPVlBQkIXVAQAAACjNMjIydMcdd+jUqVMKCwsrdO4VFYIKOhIUHR2t48ePX/CNWs3pdGrZsmXq2rWrfH19PVpLWUR/rUePrUV/rUV/rUV/rUV/rUV/rVWa+puSkqKKFSteVAi6ok6H8/f3l7+/f75xX19fjzc9T2mqpSyiv9ajx9aiv9aiv9aiv9aiv9aiv9YqDf0tyvb5niAAAAAAtuLRI0FpaWnas2eP6/n+/fu1ZcsWlS9fXldddZUHKwMAAABQVnk0BG3cuFGdOnVyPX/ooYckSfHx8UpKSvJQVQAAAADKMo+GoI4dO6qU3JcBAAAAgE1wTRAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVH08XUCYYI6WnyzszU0pPl3x9PV1R2eN00l+r0WNr0V9r0V9r0V9r0V9r0V9r5fXXGE9XUiQOY66wis+RkpKi8PBwnTp1SmFhYZ4rJD1dCgnx3PYBAAAAD3L+8Yd8IyI8WkNRsgGnwwEAAACwFU6HKwlBQXL+8YeWLl2quLg4+XKotcQ5nU76azF6bC36ay36ay36ay36ay36ay1Xf4OCPF1KkRCCSoLDIQUHKycgQAoO5nxTKzid9Ndq9Nha9Nda9Nda9Nda9Nda9Ndaef11ODxdSZFwOhwAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAWyEEAQAAALAVQhAAAAAAW/HxdAGXwhgjSUpJSfFwJZLT6VRGRoZSUlLk6+vr6XLKHPprPXpsLfprLfprLfprLfprLfprrdLU37xMkJcRCnNFh6DU1FRJUnR0tIcrAQAAAFAapKamKjw8vNA5DnMxUamUys3N1c8//6zQ0FA5HA6P1pKSkqLo6GgdPnxYYWFhHq2lLKK/1qPH1qK/1qK/1qK/1qK/1qK/1ipN/TXGKDU1VVWrVpWXV+FX/VzRR4K8vLxUvXp1T5fhJiwszOM7QFlGf61Hj61Ff61Ff61Ff61Ff61Ff61VWvp7oSNAebgxAgAAAABbIQQBAAAAsBVCUAnx9/fX2LFj5e/v7+lSyiT6az16bC36ay36ay36ay36ay36a60rtb9X9I0RAAAAAKCoOBIEAAAAwFYIQQAAAABshRAEAAAAwFYIQQAAAABshRBUiFdeeUU1atRQQECA2rRpo2+//bbQ+fPnz1e9evUUEBCgxo0ba9GiRW7LjTEaM2aMoqKiFBgYqC5dumj37t1WvoVSrSj9ffPNN3XttdeqXLlyKleunLp06ZJvfkJCghwOh9uje/fuVr+NUqso/U1KSsrXu4CAALc57L/uitLfjh075uuvw+FQz549XXPYf/+0evVq9erVS1WrVpXD4dDChQsv+JqVK1eqRYsW8vf319/+9jclJSXlm1PU3+llVVH7u2DBAnXt2lWRkZEKCwtT27ZttXTpUrc548aNy7f/1qtXz8J3UXoVtb8rV64s8PfDL7/84jaP/fesova3oN+tDodDDRs2dM1h//3T888/r9atWys0NFSVKlVSnz59tGvXrgu+7kr8DEwIOo958+bpoYce0tixY7Vp0yY1bdpUcXFxOnbsWIHz165dqwEDBujuu+/W5s2b1adPH/Xp00fbt293zZk8ebKmT5+u1157TevXr1dwcLDi4uKUmZl5ud5WqVHU/q5cuVIDBgzQihUrtG7dOkVHR6tbt2766aef3OZ1795dR48edT3mzJlzOd5OqVPU/kpnv+n53N4dPHjQbTn775+K2t8FCxa49Xb79u3y9vbWbbfd5jaP/fes9PR0NW3aVK+88spFzd+/f7969uypTp06acuWLRo1apSGDBni9kG9OH8nyqqi9nf16tXq2rWrFi1apO+++06dOnVSr169tHnzZrd5DRs2dNt/v/76ayvKL/WK2t88u3btcutfpUqVXMvYf/9U1P7++9//duvr4cOHVb58+Xy/f9l/z1q1apWGDx+ub775RsuWLZPT6VS3bt2Unp5+3tdcsZ+BDQp09dVXm+HDh7ue5+TkmKpVq5rnn3++wPm333676dmzp9tYmzZtzLBhw4wxxuTm5poqVaqYKVOmuJafPHnS+Pv7mzlz5ljwDkq3ovb3r86cOWNCQ0PNO++84xqLj483vXv3LulSr0hF7e/MmTNNeHj4edfH/uvuUvffF154wYSGhpq0tDTXGPtvwSSZ5OTkQuf885//NA0bNnQb69evn4mLi3M9v9Q/s7LqYvpbkAYNGpjExETX87Fjx5qmTZuWXGFlxMX0d8WKFUaS+eOPP847h/23YMXZf5OTk43D4TAHDhxwjbH/nt+xY8eMJLNq1arzzrlSPwNzJKgA2dnZ+u6779SlSxfXmJeXl7p06aJ169YV+Jp169a5zZekuLg41/z9+/frl19+cZsTHh6uNm3anHedZVVx+vtXGRkZcjqdKl++vNv4ypUrValSJdWtW1f33nuvTpw4UaK1XwmK29+0tDTFxMQoOjpavXv31g8//OBaxv77p5LYf99++231799fwcHBbuPsv8Vzod+/JfFnhj/l5uYqNTU13+/f3bt3q2rVqqpVq5YGDhyoQ4cOeajCK1OzZs0UFRWlrl27as2aNa5x9t+S9fbbb6tLly6KiYlxG2f/LdipU6ckKd/f93NdqZ+BCUEFOH78uHJyclS5cmW38cqVK+c7RzfPL7/8Uuj8vP8WZZ1lVXH6+1ejR49W1apV3f5Cde/eXe+++66++OILTZo0SatWrVKPHj2Uk5NTovWXdsXpb926dfWf//xHH3/8sd577z3l5uaqXbt2OnLkiCT233Nd6v777bffavv27RoyZIjbOPtv8Z3v929KSopOnz5dIr9z8KepU6cqLS1Nt99+u2usTZs2SkpK0pIlSzRjxgzt379f1157rVJTUz1Y6ZUhKipKr732mj766CN99NFHio6OVseOHbVp0yZJJfNvJs76+eeftXjx4ny/f9l/C5abm6tRo0apffv2atSo0XnnXamfgX08tmWgmCZOnKi5c+dq5cqVbhfv9+/f3/Vz48aN1aRJE9WuXVsrV65U586dPVHqFaNt27Zq27at63m7du1Uv359vf7665owYYIHKyt73n77bTVu3FhXX3212zj7L64Es2fPVmJioj7++GO3a1Z69Ojh+rlJkyZq06aNYmJi9MEHH+juu+/2RKlXjLp166pu3bqu5+3atdPevXv1wgsvaNasWR6srOx55513FBERoT59+riNs/8WbPjw4dq+fXuZvT6KI0EFqFixory9vfXrr7+6jf/666+qUqVKga+pUqVKofPz/luUdZZVxelvnqlTp2rixIn6/PPP1aRJk0Ln1qpVSxUrVtSePXsuueYryaX0N4+vr6+aN2/u6h37758upb/p6emaO3fuRf2jatf9tzjO9/s3LCxMgYGBJfJ3AtLcuXM1ZMgQffDBB/lOffmriIgI1alTh/23mK6++mpX79h/S4YxRv/5z380aNAg+fn5FTqX/VcaMWKEPv30U61YsULVq1cvdO6V+hmYEFQAPz8/tWzZUl988YVrLDc3V1988YXb/y0/V9u2bd3mS9KyZctc82vWrKkqVaq4zUlJSdH69evPu86yqjj9lc7eWWTChAlasmSJWrVqdcHtHDlyRCdOnFBUVFSJ1H2lKG5/z5WTk6Nt27a5esf++6dL6e/8+fOVlZWlO++884Lbsev+WxwX+v1bEn8n7G7OnDm66667NGfOHLdbu59PWlqa9u7dy/5bTFu2bHH1jv23ZKxatUp79uy5qP8JZef91xijESNGKDk5WV9++aVq1qx5wddcsZ+BPXZLhlJu7ty5xt/f3yQlJZkdO3aYoUOHmoiICPPLL78YY4wZNGiQeeyxx1zz16xZY3x8fMzUqVPNzp07zdixY42vr6/Ztm2ba87EiRNNRESE+fjjj833339vevfubWrWrGlOnz592d+fpxW1vxMnTjR+fn7mww8/NEePHnU9UlNTjTHGpKammkceecSsW7fO7N+/3yxfvty0aNHCxMbGmszMTI+8R08qan8TExPN0qVLzd69e813331n+vfvbwICAswPP/zgmsP++6ei9jfPNddcY/r165dvnP3XXWpqqtm8ebPZvHmzkWSmTZtmNm/ebA4ePGiMMeaxxx4zgwYNcs3ft2+fCQoKMo8++qjZuXOneeWVV4y3t7dZsmSJa86F/szspKj9ff/9942Pj4955ZVX3H7/njx50jXn4YcfNitXrjT79+83a9asMV26dDEVK1Y0x44du+zvz9OK2t8XXnjBLFy40Ozevdts27bNjBw50nh5eZnly5e75rD//qmo/c1z5513mjZt2hS4TvbfP917770mPDzcrFy50u3ve0ZGhmtOWfkMTAgqxEsvvWSuuuoq4+fnZ66++mrzzTffuJZ16NDBxMfHu83/4IMPTJ06dYyfn59p2LCh+eyzz9yW5+bmmqefftpUrlzZ+Pv7m86dO5tdu3ZdjrdSKhWlvzExMUZSvsfYsWONMcZkZGSYbt26mcjISOPr62tiYmLMPffcY8t/IPIUpb+jRo1yza1cubK54YYbzKZNm9zWx/7rrqi/H3788UcjyXz++ef51sX+6y7vlsF/feT1ND4+3nTo0CHfa5o1a2b8/PxMrVq1zMyZM/Ott7A/Mzspan87dOhQ6Hxjzt6SPCoqyvj5+Zlq1aqZfv36mT179lzeN1ZKFLW/kyZNMrVr1zYBAQGmfPnypmPHjubLL7/Mt17237OK8/vh5MmTJjAw0LzxxhsFrpP9908F9VaS2+/UsvIZ2GGMMZYdZgIAAACAUoZrggAAAADYCiEIAAAAgK0QggAAAADYCiEIAAAAgK0QggAAAADYCiEIAAAAgK0QggAAAADYCiEIAAAAgK0QggAAAADYCiEIAHBZOZ1OJSUl6ZprrlFkZKQCAwPVpEkTTZo0SdnZ2Z4uDwBgAw5jjPF0EQAA+9iyZYsefvhh3XfffWrevLkyMzO1bds2jRs3TlFRUVq6dKl8fX09XSYAoAzjSBAA4LJq1KiRvvjiC91yyy2qVauWGjRooH79+mn16tXavn27XnzxRUmSw+Eo8DFq1CjXuv744w8NHjxY5cqVU1BQkHr06KHdu3e7lv/jH/9QkyZNlJWVJUnKzs5W8+bNNXjwYNec0aNHq06dOgoKClKtWrX09NNPy+l0XpZeAAA8gxAEALisfHx8ChyPjIzUzTffrPfff981NnPmTB09etT1aNu2rdtrEhIStHHjRn3yySdat26djDG64YYbXCFm+vTpSk9P12OPPSZJevLJJ3Xy5Em9/PLLrnWEhoYqKSlJO3bs0L///W+9+eabeuGFF0r6bQMASpGC/yUCAMBiDRs21MGDB93GnE6nvL29Xc8jIiJUpUoV13M/Pz/Xz7t379Ynn3yiNWvWqF27dpKk999/X9HR0Vq4cKFuu+02hYSE6L333lOHDh0UGhqqF198UStWrFBYWJhrPU899ZTr5xo1auiRRx7R3Llz9c9//rPE3zMAoHQgBAEAPGLRokX5TjubPHmy3nvvvYt6/c6dO+Xj46M2bdq4xipUqKC6detq586drrG2bdvqkUce0YQJEzR69Ghdc801buuZN2+epk+frr179yotLU1nzpxxC0kAgLKHEAQA8IiYmJh8Y3v37lWdOnVKdDu5ublas2aNvL29tWfPHrdl69at08CBA5WYmKi4uDiFh4dr7ty5+te//lWiNQAASheuCQIAXFa///67UlNT841v3LhRK1as0B133HFR66lfv77OnDmj9evXu8ZOnDihXbt2qUGDBq6xKVOm6Mcff9SqVau0ZMkSzZw507Vs7dq1iomJ0ZNPPqlWrVopNjY23yl6AICyhxAEALisDh06pGbNmuntt9/Wnj17tG/fPs2aNUu9e/fWtdde63b3t8LExsaqd+/euueee/T1119r69atuvPOO1WtWjX17t1bkrR582aNGTNGb731ltq3b69p06Zp5MiR2rdvn2sdhw4d0ty5c7V3715Nnz5dycnJVr11AEApQQgCAFxWjRo10tixY5WUlKS///3vatiwoSZPnqwRI0bo888/d7v5wYXMnDlTLVu21I033qi2bdvKGKNFixbJ19dXmZmZuvPOO5WQkKBevXpJkoYOHapOnTpp0KBBysnJ0U033aQHH3xQI0aMULNmzbR27Vo9/fTTVr11AEApwZelAgAAALAVjgQBAAAAsBVCEAAAAABbIQQBAAAAsBVCEAAAAABbIQQBAAAAsBVCEAAAAABbIQQBAAAAsBVCEAAAAABbIQQBAAAAsBVCEAAAAABbIQQBAAAAsJX/Bw2x8Ae4JlCGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "# Set train params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "model_id = \"microsoft/renderformer-v1.1-swin-large\"\n",
    "pipeline = RenderFormerRenderingPipeline.from_pretrained(model_id)\n",
    "\n",
    "if device == torch.device('cuda') and os.name == 'posix':  # avoid windows\n",
    "    from renderformer_liger_kernel import apply_kernels\n",
    "    apply_kernels(pipeline.model)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "elif device == torch.device('mps'):\n",
    "    precision = 'fp32'\n",
    "    print(\"bf16 and fp16 will cause too large error in MPS, force using fp32 instead.\")\n",
    "\n",
    "# Start training\n",
    "trainer = train_model(pipeline, num_epochs=3, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d80c1",
   "metadata": {},
   "source": [
    "# Clear CUDA cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f0e4e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кэш CUDA очищен\n",
      "Сборка мусора выполнена\n"
     ]
    }
   ],
   "source": [
    "# Очистка кэша и памяти CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Кэш CUDA очищен\")\n",
    "\n",
    "# Очистка памяти Python\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"Сборка мусора выполнена\")\n",
    "\n",
    "# Дополнительная очистка для MPS (если используется)\n",
    "if torch.backends.mps.is_available() and device == torch.device('mps'):\n",
    "    torch.mps.empty_cache()\n",
    "    print(\"Кэш MPS очищен\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
