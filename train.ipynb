{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b77395f",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0624786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Please install it from https://github.com/Dao-AILab/flash-attention.\n",
      "Falling back to sdpa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devel/.draft/renderformer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from renderformer import RenderFormerRenderingPipeline\n",
    "from renderformer.models.renderformer import RenderFormer\n",
    "from renderformer.models.config import RenderFormerConfig\n",
    "\n",
    "from simple_ocio import ToneMapper\n",
    "import blenderproc as bproc\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from math import radians\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47f241",
   "metadata": {},
   "source": [
    "# Generate syntetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cc19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from generate_dataset import SceneGenerator\n",
    "# import asyncio\n",
    "\n",
    "\n",
    "# CONFIG = {\n",
    "#     \"DATA_PATH\": \"/home/devel/.draft/renderformer/datasets\",\n",
    "#     \"JSON_PATH\": \"/home/devel/.draft/renderformer/datasets/json\",\n",
    "#     \"H5_PATH\": \"/home/devel/.draft/renderformer/datasets/h5\",\n",
    "#     \"GT_PATH\": \"/home/devel/.draft/renderformer/datasets/gt\",\n",
    "#     \"TEMP_MESH_PATH\": \"/home/devel/.draft/renderformer/datasets/temp\",\n",
    "#     \"OBJ_PATH\": \"/home/devel/.draft/renderformer/examples/objects\",\n",
    "#     \"BASE_DIR\": \"/home/devel/.draft/renderformer/examples\",\n",
    "#     \"SCRIPT_NAME\": \"render_scene.py\",\n",
    "#     \"NUM_RANDOM_SCENES\": 5,\n",
    "#     \"MAX_CONCURRENT_TASKS\": 4,\n",
    "# }\n",
    "\n",
    "\n",
    "# generator = SceneGenerator(CONFIG)\n",
    "\n",
    "# # Asynchronous generation\n",
    "# await generator.generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4f705",
   "metadata": {},
   "source": [
    "# Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a96df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_h5_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        triangles = torch.from_numpy(np.array(f['triangles']).astype(np.float32))\n",
    "        num_tris = triangles.shape[0]\n",
    "        texture = torch.from_numpy(np.array(f['texture']).astype(np.float32))\n",
    "        mask = torch.ones(num_tris, dtype=torch.bool)\n",
    "        vn = torch.from_numpy(np.array(f['vn']).astype(np.float32))\n",
    "        c2w = torch.from_numpy(np.array(f['c2w']).astype(np.float32))\n",
    "        fov = torch.from_numpy(np.array(f['fov']).astype(np.float32))\n",
    "\n",
    "        data = {\n",
    "            'triangles': triangles,\n",
    "            'texture': texture,\n",
    "            'mask': mask,\n",
    "            'c2w': c2w,\n",
    "            'fov': fov,\n",
    "            'vn': vn,\n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b04c3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'triangles' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Load data and move to device\u001b[39;00m\n\u001b[1;32m     46\u001b[0m h5_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/devel/.draft/renderformer/tmp/random_scene_0_obj3.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 47\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_single_h5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Add batch dimension to all tensors\u001b[39;00m\n\u001b[1;32m     50\u001b[0m triangles \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriangles\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mload_single_h5_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_single_h5_data\u001b[39m(file_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m         triangles \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtriangles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m      4\u001b[0m         num_tris \u001b[38;5;241m=\u001b[39m triangles\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m         texture \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexture\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.draft/renderformer/.venv/lib/python3.10/site-packages/h5py/_hl/group.py:360\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 360\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'triangles' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# Создание конфигурации\n",
    "config = RenderFormerConfig(\n",
    "    latent_dim=768,\n",
    "    num_layers=12,\n",
    "    num_heads=6,\n",
    "    dim_feedforward=768 * 4,\n",
    "    num_register_tokens=16,\n",
    "    dropout=0.0,\n",
    "    activation='swiglu',\n",
    "    norm_type='rms_norm',\n",
    "    norm_first=True,\n",
    "    pe_type='rope',\n",
    "    rope_type='triangle',\n",
    "    use_vn_encoder=True,\n",
    "    texture_encode_patch_size=32,\n",
    "    texture_channels=13,\n",
    "    view_transformer_latent_dim=768,\n",
    "    view_transformer_ffn_hidden_dim=768 * 4,\n",
    "    view_transformer_n_heads=6,\n",
    "    view_transformer_n_layers=6,\n",
    "    patch_size=8,\n",
    "    use_dpt_decoder=True\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# Инициализация модели\n",
    "model = RenderFormer(config)\n",
    "model.to(device)\n",
    "\n",
    "# Подготовка входных данных\n",
    "batch_size = 1\n",
    "max_num_tri = 1000\n",
    "num_views = 1\n",
    "\n",
    "tri_vpos_list = torch.randn(batch_size, max_num_tri, 9).cuda()\n",
    "texture_patch_list = torch.randn(batch_size, max_num_tri, 13, 32, 32).cuda()\n",
    "valid_mask = torch.ones(batch_size, max_num_tri, dtype=torch.bool).cuda()\n",
    "vns = torch.randn(batch_size, max_num_tri, 3, 3).cuda()\n",
    "rays_o = torch.randn(batch_size, num_views, 3).cuda()\n",
    "rays_d = torch.randn(batch_size, num_views, 512, 512, 3).cuda()\n",
    "tri_vpos_view_tf = torch.randn(batch_size, num_views, max_num_tri, 9).cuda()\n",
    "\n",
    "\n",
    "# Load data and move to device\n",
    "h5_file = '/home/devel/.draft/renderformer/tmp/random_scene_0_obj3.h5'\n",
    "data = load_single_h5_data(h5_file)\n",
    "\n",
    "# Add batch dimension to all tensors\n",
    "triangles = data['triangles'].unsqueeze(0).to(device)\n",
    "texture = data['texture'].unsqueeze(0).to(device)\n",
    "mask = data['mask'].unsqueeze(0).to(device)\n",
    "vn = data['vn'].unsqueeze(0).to(device)\n",
    "c2w = data['c2w'].unsqueeze(0).to(device)\n",
    "fov = data['fov'].unsqueeze(0).unsqueeze(-1).to(device)\n",
    "resolution = 512\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "pipeline = RenderFormerRenderingPipeline(model)\n",
    "\n",
    "\n",
    "rendered_imgs = pipeline(\n",
    "    triangles=triangles,\n",
    "    texture=texture,\n",
    "    mask=mask,\n",
    "    vn=vn,\n",
    "    c2w=c2w,\n",
    "    fov=fov,\n",
    "    resolution=resolution,\n",
    "    torch_dtype=torch_dtype,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
